\section{Midi Connectivity}
In order for the user to be able to easily change the drum sound profile it would make sense to work towards a MIDI configuration. Here the analogue signal from the FSR sensors needs to go through a AD converter and preferably to a device which also has either a WiFi or Bluetooth module built in. This way the digital signal is able to be sent to a MIDI software which translates the signal into the chosen sound. There are countless ways to expand the interactions possible so that the sounds are not only limited to playing drum sounds partly because we plan on using FSR sensors. Via MIDI it is possible to play whatever you like and the FSRs make it possible to vary the intensity of the sound in relation to how hard you press or even modulate pitch eg. if synthesised sounds are being played. As of now the prototype has a very small but noticable delay between being pushed and the sound being played. According to \parencite{Adelstein2003} the maximum delay in haptic to audio asynchrony is 24 ms. This means that the maximum delay between a person hitting a drum and noticing that the sound is delayed is 24 ms. In order to completely avoid having the user experience haptic to audio asynchrony it would be preferable to make it a requirement that the maximum allowable delay between the sensors transmitting the signal and the speakers playing the sound is 15 ms. This should be quite doable.